{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Roszell_Thesis_MRI",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOq+e2xawjlb9jRGGBNvdQ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StayFrostea/LearningML/blob/main/Roszell_Thesis_MRI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMQ6IBdJ-M4T"
      },
      "source": [
        "# This is the first baseline model of the MRI Thesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzn-XX9G-eoj"
      },
      "source": [
        "### Importing the dataset from Googler Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnXDasQe-H0R"
      },
      "source": [
        "## Loading the google drive where I stored the MOSMEDDATA files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BrXTHQk-Q4J"
      },
      "source": [
        "toTrain_path = '/content/drive/MyDrive/Colab Notebooks/Data/'\n",
        "toPredict_path = '/content/drive/MyDrive/Colab Notebooks/Data/'\n",
        "\n",
        "toTrain_path_output = '/content/drive/MyDrive/Colab Notebooks/Data/'\n",
        "toPredict_path_output = '/content/drive/MyDrive/Colab Notebooks/Data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOlKQjal-qwU"
      },
      "source": [
        "### Sectioning off some of the data for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncTbUP4m-2Df"
      },
      "source": [
        "## A tool for spliting the image files before processing\n",
        "!pip install split-folders\n",
        "import splitfolders\n",
        "\n",
        "## 80/20 Split of the data\n",
        "splitfolders.ratio(toTrain_path, output=toTrain_path_output, seed=1337, ratio=(0.8, 0.2))\n",
        "splitfolders.ratio(toPredict_path, output=toPredict_path_output, seed=1337, ratio=(0.8, 0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkadyJFLBhXX"
      },
      "source": [
        "import os\n",
        "\n",
        "## First class files\n",
        "path, dirs, files = next(os.walk(abnormal_path_output + '/train/class1'))\n",
        "file_count = len(files)\n",
        "file_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRdWABALBt4J"
      },
      "source": [
        "## Second class files\n",
        "path, dirs, files = next(os.walk(abnormal_path_output + '/train/class2'))\n",
        "file_count = len(files)\n",
        "file_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UBEoQS1B66r"
      },
      "source": [
        "## Read Function\n",
        "def read_NifTi(fp):\n",
        "    scan = nib.load(fp)\n",
        "    scan = scan.get_fdata()\n",
        "    return scan\n",
        "\n",
        "## Resize function\n",
        "def resizeVolume(img):\n",
        "\n",
        "    ## desired\n",
        "    d_depth = 64\n",
        "    d_width = 150\n",
        "    d_height = 150\n",
        "\n",
        "    ## current\n",
        "    c_depth = img.shape[-1]\n",
        "    c_width = img.shape[0]\n",
        "    c_height = img.shape[1]\n",
        "\n",
        "    ## factor to change by\n",
        "    d_factor = d_depth/c_depth\n",
        "    w_factor = d_width/c_width\n",
        "    h_factor = d_height/c_height\n",
        "\n",
        "    ## Adjust proper rotation\n",
        "    img = ndimage.rotate(img, 90, reshape = False)\n",
        "\n",
        "    ## apply the factors\n",
        "    img = ndimage.zoom(img, (w_factor, h_factor, d_factor), order = 1)\n",
        "\n",
        "    return img\n",
        "  \n",
        "## Normalize Function\n",
        "def normalizeVolume(vol):\n",
        "    min = -1000\n",
        "    max = 400\n",
        "    vol[vol < min] = min\n",
        "    vol[vol > max] = max\n",
        "    vol = (vol - min) / (max - min)\n",
        "    vol = vol.astype(\"float32\")\n",
        "    return vol\n",
        "\n",
        "## Processing Function\n",
        "def processVolume(path):\n",
        "    volume = read_NifTi(path)\n",
        "    volume = normalizeVolume(volume)\n",
        "    volume = resizeVolume(volume)\n",
        "    return volume"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcXv6BNtCA_5"
      },
      "source": [
        "## Setting up the filepaths for each file in class 1\n",
        "normal_scan_paths = [\n",
        "    os.path.join(os.getcwd(), normal_path_output + '/train/class1', x)\n",
        "    for x in os.listdir(normal_path_output + '/train/class1')\n",
        "]\n",
        "\n",
        "## Setting up the filepaths for each file in class 2\n",
        "alzheimer_scan_paths = [\n",
        "    os.path.join(os.getcwd(), normal_path_output + '/train/class2', x)\n",
        "    for x in os.listdir(normal_path_output + '/train/class2')\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPyj7hoACFFY"
      },
      "source": [
        "## Normal Subject files into numpy arrays\n",
        "normal_volumes = np.array([processVolume(path) for path in normal_scan_paths])\n",
        "normal_volume_labels = np.array([0 for _ in range(len(normal_volumes))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt0xJWo2DOtI"
      },
      "source": [
        "## Alzheimer's Subject files into numpy arrays\n",
        "alzheimer_volumes = np.array([processVolume(path) for path in alzheimer_scan_paths])\n",
        "alzheimer_volume_labels = np.array([1 for _ in range(len(alzheimer_volumes))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tAP4M5HDqoH"
      },
      "source": [
        "print(\"CT scans with normal lung tissue: \" + str(len(normal_scan_paths)))\n",
        "print(\"CT scans with abnormal lung tissue: \" + str(len(alzheimer_scan_paths)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-Qr0hBfGtYV"
      },
      "source": [
        "## 60/20 Split of volumes\n",
        "X_train = np.concatenate((abnormal_volumes[:60], normal_volumes[:60]), axis=0)\n",
        "y_train = np.concatenate((abnormal_volume_labels[:60], normal_volume_labels[:60]), axis=0)\n",
        "\n",
        "X_val = np.concatenate((abnormal_volumes[60:], normal_volumes[60:]), axis=0)\n",
        "y_val = np.concatenate((abnormal_volume_labels[60:], normal_volume_labels[60:]), axis=0)\n",
        "\n",
        "print(   \n",
        "\"Number of samples in train and validation are %d and %d.\"\n",
        "    % (X_train.shape[0], X_val.shape[0])\n",
        ")\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiNsMKd0HtEn"
      },
      "source": [
        "### Preprocessing Directives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umqdOMSCHZLj"
      },
      "source": [
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxV_Tgo4Hdzt"
      },
      "source": [
        "## Rotation Augmentation\n",
        "def rotate(volume):\n",
        "\n",
        "    def scipy_rotate(volume):\n",
        "        # define some rotation angles\n",
        "        angles = [-20, -10, -5, 5, 10, 20]\n",
        "        # pick angles at random\n",
        "        angle = random.choice(angles)\n",
        "        # rotate volume\n",
        "        volume = ndimage.rotate(volume, angle, reshape=False)\n",
        "        volume[volume < 0] = 0\n",
        "        volume[volume > 1] = 1\n",
        "        return volume\n",
        "\n",
        "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
        "    return augmented_volume"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wj7QiliH1vZ"
      },
      "source": [
        "## For now we will not do preprocessing\n",
        "## Only add the the stack to match dimensionality\n",
        "\n",
        "def train_preprocess(volume, label):\n",
        "  # volume = rotate(volume)\n",
        "  volume = tf.stack((volume,)*3, axis = 3)\n",
        "  return volume, label\n",
        "def valid_preprocess(volume, label):\n",
        "  volume = tf.stack((volume,)*3, axis = 3)\n",
        "  return volume, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FF5evksIWhE"
      },
      "source": [
        "## Run the preprocessing Steps\n",
        "X_train_r, y_train_r = train_preprocess(X_train, y_train)\n",
        "X_val_r, y_val_r = valid_preprocess(X_val, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5VLJfogJYH-"
      },
      "source": [
        "## Slicing Function\n",
        "def threeDToTwoD(threeDVol, numVol):\n",
        "\n",
        "  twoDVol = np.zeros((numVol*64, 150, 150, 3), np.float32)\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  for i in range(numVol):\n",
        "    for j in range(64):\n",
        "      twoDVol[count] = threeDVol[i,:,:,:,j]\n",
        "      count = count + 1\n",
        "\n",
        "  return twoDVol"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBgkmVZqKioT"
      },
      "source": [
        "## Extending Labels to Match\n",
        "def extendLabels(labelArr, numVol):\n",
        "\n",
        "  newLabelArr = np.zeros((numVol * 64), np.float32)\n",
        "\n",
        "  for i in range(numVol):\n",
        "    for j in range(64):\n",
        "      newLabelArr[(i*64)+j] = labelArr[i]\n",
        "\n",
        "  return newLabelArr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKnfxcEFKMGQ"
      },
      "source": [
        "## New arrays\n",
        "\n",
        "## First the training images\n",
        "X_train_f = threeDToTwoD(X_train_r, 120)\n",
        "\n",
        "## Second the validation images\n",
        "X_val_f = threeDToTwoD(X_val_r, 40)\n",
        "\n",
        "## Third the training labels\n",
        "y_train_f = extendLabels(y_train_r, 120)\n",
        "\n",
        "## Fourth the validation labels\n",
        "y_val_f = extendLabels(y_val_r, 40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdMslY6dK96k"
      },
      "source": [
        "### Now the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10glJ2BtLCTr"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mb9wIJOLqeH"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential(\n",
        "    [layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.1),])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWyVyORaLs1g"
      },
      "source": [
        "## The model build\n",
        "def buildModel():\n",
        "\n",
        "  initial_model = tf.keras.applications.Xception(\n",
        "      weights = 'imagenet',\n",
        "      input_shape = (150,150,3),\n",
        "      include_top = False)\n",
        "  \n",
        "  ## Freeze the pretrained model parameters\n",
        "  initial_model.trainable = False\n",
        "\n",
        "  inputs = tf.keras.Input(shape = (150,150,3))\n",
        "\n",
        "  x = data_augmentation(inputs)\n",
        "\n",
        "  scale_layer = tf.keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
        "  x = scale_layer(x)\n",
        "\n",
        "  x = initial_model(inputs, training = False)\n",
        "  x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "  outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs, outputs)\n",
        "  return model\n",
        "\n",
        "model = buildModel()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Che8qwfAL1tK"
      },
      "source": [
        "## Setting up the fit parameters\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    0.0001, decay_steps=100000, decay_rate=0.96, staircase=True\n",
        ")\n",
        "\n",
        "model.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "              metrics = tf.keras.metrics.BinaryAccuracy(),\n",
        "              )\n",
        "\n",
        "## Defining checkpoints\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"3D_CT_classification.h5\", save_best_only=True\n",
        ")\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "\n",
        "## How man runs\n",
        "epochs = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t64xs7N1L2Yv"
      },
      "source": [
        "## Training the model\n",
        "model.fit(x = X_train_f,\n",
        "          y = y_train_f,\n",
        "          validation_data=(X_val_f, y_val_f),\n",
        "          epochs=epochs,\n",
        "          shuffle=True,\n",
        "          verbose='auto',\n",
        "          callbacks = [ checkpoint_cb , early_stopping_cb],\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}