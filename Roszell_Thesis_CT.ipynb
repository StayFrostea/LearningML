{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Roszell_Thesis_CT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMfDT5Uc5yyJTjPyoJrdPxp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StayFrostea/LearningML/blob/main/Roszell_Thesis_CT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXcf-DnmL4y8"
      },
      "source": [
        "## Loading in the images from goodle drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muZW-q4Ji8Zr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f070f4cc-adce-472c-e4ad-d246e084e187"
      },
      "source": [
        "## Loading the google drive where I stored the MOSMEDDATA files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CN4UqYKmhVI",
        "outputId": "b48cd3f8-ea22-495f-bca5-b9d2da93d149"
      },
      "source": [
        "## Paths for the data\n",
        "\n",
        "normal_path = '/content/drive/MyDrive/Colab Notebooks/Data/Keras CT'\n",
        "abnormal_path = '/content/drive/MyDrive/Colab Notebooks/Data/Keras CT'\n",
        "\n",
        "normal_path_output = '/content/drive/MyDrive/Colab Notebooks/Data/Keras CT/output'\n",
        "abnormal_path_output = '/content/drive/MyDrive/Colab Notebooks/Data/Keras CT/output'\n",
        "len(normal_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cIqCA7BL_ti"
      },
      "source": [
        "## Splitting the \"files\" into seperate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAlX8B9Jsw3j",
        "outputId": "37c9dac7-c689-4590-a6eb-100070995a9e"
      },
      "source": [
        "## A tool for spliting the image files before processing\n",
        "\n",
        "!pip install split-folders "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.4.3-py3-none-any.whl (7.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E8d0lm3nVki"
      },
      "source": [
        "## Next up is to load the images into seperated folders\n",
        "## I want 90% of them to be invoplved in the train/validate split\n",
        "## Then I want 10% of them to never be touched by the model till I predict\n",
        "## I want to also split them before I slice them down into 2d chunks\n",
        "\n",
        "##import splitfolders\n",
        "\n",
        "##splitfolders.ratio(normal_path, output=normal_path_output, seed=1337, ratio=(0.8, 0.2))\n",
        "##splitfolders.ratio(abnormal_path, output=abnormal_path_output, seed=1337, ratio=(0.8, 0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXBN25XNoTer",
        "outputId": "b911430e-e39b-43dc-cf42-d9420a29bd2d"
      },
      "source": [
        "## Check how many files got split up\n",
        "import os\n",
        "\n",
        "path, dirs, files = next(os.walk(abnormal_path_output + '/val/class1'))\n",
        "file_count = len(files)\n",
        "file_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1O0K0UlJPI8",
        "outputId": "6c880c9b-5fc4-4ab1-fd95-c5a595fb6756"
      },
      "source": [
        "path, dirs, files = next(os.walk(abnormal_path_output + '/train/class1'))\n",
        "file_count = len(files)\n",
        "file_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0PAPBAQLrbE"
      },
      "source": [
        "## Now we are ready to load the files into the notebook as NifTi images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNMquv-JJVAY"
      },
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from nibabel.testing import data_path\n",
        "from scipy import ndimage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxqS8_EBNEOo"
      },
      "source": [
        "def read_NifTi(fp):\n",
        "    scan = nib.load(fp)\n",
        "    scan = scan.get_fdata()\n",
        "    return scan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lmA6KlIQV6C"
      },
      "source": [
        "def resizeVolume(vol):\n",
        "\n",
        "    ## desired\n",
        "    d_depth = 64\n",
        "    d_width = 128\n",
        "    d_height = 128\n",
        "\n",
        "    ## current\n",
        "    c_depth = vol.shape[-1]\n",
        "    c_width = vol.shape[0]\n",
        "    c_height = vol.shape[1]\n",
        "\n",
        "    ## factor to change by\n",
        "    d_factor = d_depth/c_depth\n",
        "    w_factor = d_width/c_width\n",
        "    h_factor = d_height/c_height\n",
        "\n",
        "    ## Adjust proper rotation\n",
        "    vol = ndimage.rotate(vol, 90, reshape = False)\n",
        "\n",
        "    ## apply the factors\n",
        "    vol = ndimage.zoom(vol, (w_factor, h_factor, d_factor), order = 1)\n",
        "\n",
        "    return vol"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HxhXUCVTCtL"
      },
      "source": [
        "def normalizeVolume(vol):\n",
        "    min = -1000\n",
        "    max = 400\n",
        "    vol[vol < min] = min\n",
        "    vol[vol > max] = max\n",
        "    vol = (vol - min) / (max - min)\n",
        "    vol = vol.astype(\"float32\")\n",
        "    return vol"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKm0rI3EXHUP"
      },
      "source": [
        "def processVolume(path):\n",
        "    volume = read_NifTi(path)\n",
        "    volume = normalizeVolume(volume)\n",
        "    volume = resizeVolume(volume)\n",
        "    return volume"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EEykgTXR6nS"
      },
      "source": [
        "normal_scan_paths = [\n",
        "    os.path.join(os.getcwd(), normal_path_output + '/train/class1', x)\n",
        "    for x in os.listdir(normal_path_output + '/train/class1')\n",
        "]\n",
        "\n",
        "abnormal_scan_paths = [\n",
        "    os.path.join(os.getcwd(), abnormal_path_output + '/train/class1', x)\n",
        "    for x in os.listdir(abnormal_path_output + '/train/class1')\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljUGNBjXXdB7"
      },
      "source": [
        "## Normal\n",
        "normal_volumes = np.array([processVolume(path) for path in normal_scan_paths])\n",
        "normal_volume_labels = np.array([0 for _ in range(len(normal_volumes))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKqufSD5YMMc"
      },
      "source": [
        "## abNormal\n",
        "abnormal_volumes = np.array([processVolume(path) for path in abnormal_scan_paths])\n",
        "abnormal_volume_labels = np.array([1 for _ in range(len(abnormal_volumes))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pxzi0F5mAeY",
        "outputId": "333df94a-ac64-44b6-a156-b0265b955d37"
      },
      "source": [
        "print(\"CT scans with normal lung tissue: \" + str(len(normal_scan_paths)))\n",
        "print(\"CT scans with abnormal lung tissue: \" + str(len(abnormal_scan_paths)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CT scans with normal lung tissue: 80\n",
            "CT scans with abnormal lung tissue: 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeqXglg2ahwX"
      },
      "source": [
        "## Now we can split the images into training and validation in order to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr__VpHGY2Pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f834e50d-4d67-4ff7-eece-b0d92ff5bc0a"
      },
      "source": [
        "## Example way\n",
        "## The [:60] means up to index 60\n",
        "## Therefore we will have a 60/20 split for train/val\n",
        "X_train = np.concatenate((abnormal_volumes[:60], normal_volumes[:60]), axis=0)\n",
        "y_train = np.concatenate((abnormal_volume_labels[:60], normal_volume_labels[:60]), axis=0)\n",
        "\n",
        "X_val = np.concatenate((abnormal_volumes[60:], normal_volumes[60:]), axis=0)\n",
        "y_val = np.concatenate((abnormal_volume_labels[60:], normal_volume_labels[60:]), axis=0)\n",
        "\n",
        "## SK way\n",
        "\n",
        "##from sklearn.model_selection import train_test_split\n",
        "\n",
        "##vol_data, vol_labels = np.arange(10).reshape((5, 2)), range(5)\n",
        "\n",
        "##X_train, y_train, X_val, y_val = train_test_split(vol_data, vol_labels, test_size=0.20, random_state=42)\n",
        "print( \n",
        "    \n",
        "\"Number of samples in train and validation are %d and %d.\"\n",
        "    % (X_train.shape[0], X_val.shape[0])\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in train and validation are 120 and 40.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23nJgkx7XKiU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNKpqjmuTxS1"
      },
      "source": [
        "## This is where I will put preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcrxVLLPUJQJ"
      },
      "source": [
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def rotate(volume):\n",
        "\n",
        "    def scipy_rotate(volume):\n",
        "        # define some rotation angles\n",
        "        angles = [-20, -10, -5, 5, 10, 20]\n",
        "        # pick angles at random\n",
        "        angle = random.choice(angles)\n",
        "        # rotate volume\n",
        "        volume = ndimage.rotate(volume, angle, reshape=False)\n",
        "        volume[volume < 0] = 0\n",
        "        volume[volume > 1] = 1\n",
        "        return volume\n",
        "\n",
        "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
        "    return augmented_volume\n",
        "\n",
        "## This is to expand dimensions by adding size 1 onto the added dimension\n",
        "##def expandDims(volume):\n",
        "  ##volume = tf.expand_dims(volume, axis=3)\n",
        "  ##return volume\n",
        "\n",
        "## We rotate at random to remove the orientation effect on the model\n",
        "def train_preprocess(volume, label):\n",
        "  volume = rotate(volume)\n",
        "  volume = tf.expand_dims(volume, axis=3)\n",
        "  return volume, label\n",
        "\n",
        "## No need to rotate the validation set\n",
        "def valid_preprocess(volume, label):\n",
        "  volume = tf.expand_dims(volume, axis=3)\n",
        "  return volume, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUYP1zz9WedP"
      },
      "source": [
        "## Using tensorflows automated data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe7KI8uVWk0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b6bfc6-ec7f-4cf5-935a-3d8d3e9765cd"
      },
      "source": [
        "## Use a library called tf.data.Dataset.from_tensor_slice\n",
        "\n",
        "train_loader = tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
        "\n",
        "valid_loader = tf.data.Dataset.from_tensor_slices((X_val,y_val))\n",
        "X_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 128, 128, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3uuN0q5YQX6"
      },
      "source": [
        "batch_size = 3\n",
        "\n",
        "train_dataset = (\n",
        "    train_loader.shuffle(len(X_train))\n",
        "    .map(train_preprocess)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(3)\n",
        ")\n",
        "\n",
        "validation_dataset = (\n",
        "    valid_loader.shuffle(len(X_val))\n",
        "    .map(valid_preprocess)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(3)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA3EB6u1fW2W"
      },
      "source": [
        "## Finally the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0R-XAWJda_t"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co_FAylTgrs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46bde40-2313-4bc7-a68a-c8f22baebc5c"
      },
      "source": [
        "def buildModel():\n",
        "\n",
        "  inputs = keras.Input((128, 128, 64, 1))\n",
        "\n",
        "  x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
        "  x = layers.MaxPool3D(pool_size=2)(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "\n",
        "  x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "  x = layers.MaxPool3D(pool_size=2)(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "\n",
        "  x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "  x = layers.MaxPool3D(pool_size=2)(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "\n",
        "  x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "  x = layers.MaxPool3D(pool_size=2)(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "\n",
        "  x = layers.GlobalAveragePooling3D()(x)\n",
        "  x = layers.Dense(units=512, activation=\"relu\")(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "\n",
        "  outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "  model = keras.Model(inputs, outputs, name=\"CT_CNN_3D\")\n",
        "  return model\n",
        "\n",
        "model = buildModel()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"CT_CNN_3D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128, 128, 64, 1)] 0         \n",
            "_________________________________________________________________\n",
            "conv3d (Conv3D)              (None, 126, 126, 62, 64)  1792      \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 63, 63, 31, 64)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 63, 63, 31, 64)    256       \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 61, 61, 29, 64)    110656    \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 30, 30, 14, 64)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 30, 30, 14, 64)    256       \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 28, 28, 12, 128)   221312    \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 14, 14, 6, 128)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 6, 128)    512       \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 12, 12, 4, 256)    884992    \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 6, 6, 2, 256)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 6, 6, 2, 256)      1024      \n",
            "_________________________________________________________________\n",
            "global_average_pooling3d (Gl (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 1,352,897\n",
            "Trainable params: 1,351,873\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nU84AIAJotI"
      },
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    0.0001, decay_steps=100000, decay_rate=0.96, staircase=True\n",
        ")\n",
        "\n",
        "model.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "              metrics = keras.metrics.BinaryAccuracy(),\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He1JzEjOK8gW"
      },
      "source": [
        "## Defining \n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    \"3D_CT_classification.h5\", save_best_only=True\n",
        ")\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='loss', patience=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD4Bc1rpaa77"
      },
      "source": [
        "## How man runs\n",
        "epochs = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFuWTen5amcm",
        "outputId": "680a5664-20ec-4222-e131-ddaa6fadef03"
      },
      "source": [
        "## Training!!!!\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          validation_data=validation_dataset,\n",
        "          epochs=epochs,\n",
        "          shuffle=True,\n",
        "          verbose='auto',\n",
        "          callbacks = [ checkpoint_cb , early_stopping_cb],\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "40/40 [==============================] - 66s 833ms/step - loss: 0.8023 - binary_accuracy: 0.4667 - val_loss: 1.3380 - val_binary_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "40/40 [==============================] - 35s 863ms/step - loss: 0.7202 - binary_accuracy: 0.5583 - val_loss: 0.7567 - val_binary_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "40/40 [==============================] - 33s 826ms/step - loss: 0.7368 - binary_accuracy: 0.5083 - val_loss: 1.6320 - val_binary_accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "40/40 [==============================] - 34s 830ms/step - loss: 0.7557 - binary_accuracy: 0.4500 - val_loss: 1.0031 - val_binary_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "40/40 [==============================] - 33s 825ms/step - loss: 0.7489 - binary_accuracy: 0.5417 - val_loss: 0.7669 - val_binary_accuracy: 0.5000\n",
            "Epoch 6/20\n",
            "40/40 [==============================] - 33s 818ms/step - loss: 0.7551 - binary_accuracy: 0.4667 - val_loss: 1.2447 - val_binary_accuracy: 0.5000\n",
            "Epoch 7/20\n",
            "40/40 [==============================] - 33s 824ms/step - loss: 0.7466 - binary_accuracy: 0.4333 - val_loss: 1.2800 - val_binary_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f833029f390>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeysufddbLCA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}